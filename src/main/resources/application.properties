server.port=8080
#============== kafka ===================
# 指定kafka 代理地址，可以多个,配置多个逗号隔开 举例：     192.168.59.130:9092,192.168.59.131:9092,192.168.59.132:9092
spring.kafka.bootstrap-servers=localhost:9092
#=============== provider  =======================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432


# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#=============== consumer  =======================
# 指定默认消费者group id，随意写
spring.kafka.consumer.group-id=testzs
#latest, earliest, none   默认是latest最新的，建议是earliest最早的
spring.kafka.consumer.auto-offset-reset=earliest
#消费者偏移量自动提交 提交的理解：更新分区当前位置的操作   fasle得时候查看包 commitfalse, 改成true,查看剩余得，这里注释了自动提交得消费者，否则报错
spring.kafka.consumer.enable-auto-commit=false
#消费者提交Kafka的频率，毫秒为单位 默认为5秒
spring.kafka.consumer.auto-commit-interval=100
#消费者拉取的消息的数量，默认50，适当的减小，是防止重复消费一种策略，可以提高消费水平
spring.kafka.consumer.max-poll-records=10
#心跳与消费者协调员之间的预期时间（以毫秒为单位），默认值为3000，适当延长，避免活锁（由于某些原因咱不能消费）
spring.kafka.consumer.heartbeat-interval=5000
# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
##在侦听器容器中运行的线程数
spring.kafka.listener.concurrency=10




